<!DOCTYPE html>
<html lang="en">

<head>
  <meta name="google-site-verification" content="wYvWtjOgtH2vemeJWG0qdpVSuGJB5wU3lk6l4sZgnpc" />
  <meta charset="utf-8">
  <meta http-equiv="Cache-control" content="public">
  <meta name="description" content="Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients">
  <meta name="keywords" content="Property Gradients, Interventions, Causality-based Explanations, XAI, Explainability">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients</title>

  <link rel="icon" href="./static/images/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/jquery-3.5.1.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script defer src="./static/js/bulma-carousel.min.js"></script>
  <script defer src="./static/js/bulma-slider.min.js"></script>
  <script defer src="./static/js/index.js"></script>
    <style type="text/css">
/*
generated by Pygments <https://pygments.org/>
Copyright 2006-2024 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: #ffffcc }
.highlight { background: #f8f8f8; }
.highlight .c { color: #3D7B7B; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #9C6500 } /* Comment.Preproc */
.highlight .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.highlight .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */
.highlight .gr { color: #E40000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #008400 } /* Generic.Inserted */
.highlight .go { color: #717171 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #687822 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #717171; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #767600 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #A45A77 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>
</head>

<body>
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://inf-cv.uni-jena.de/home/staff/">
          <span class="cvg-logo"></span>
        </a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://causalrivers.github.io/">
              ICLR 2025 - CausalRivers: Scaling up Benchmarking of Causal Discovery
            </a>
            <a class="navbar-item" href="https://eifer-mam.github.io/">
              CVPR 2025 - EIFER: Electromyography-Informed Facial Expression Reconstruction
            </a>
            <a class="navbar-item" href="https://fastcav.github.io/">
              ICML 2025 - FastCAV: Efficient Computation of Concept Activation Vectors 
            </a>
          </div>
        </div>
      </div>
    </div>
  </nav>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
              <h1 class="title is-1 publication-title"><b>Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients</b></h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=s9bfMqEAAAAJ&hl=en">Niklas Penzel<sup><small>1</small></sup></a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.de/citations?hl=en&user=bhpi3vgAAAAJ&hl=en">Joachim Denzler<sup><small>1</small></sup></a>,
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup><small>1</small></sup> Computer Vision Group Jena, Friedrich Schiller University Jena, Germany
              </span>
            </div>
            <br>
            <div class="is-size-5 publication-authors is-dark is">
              <b>
                WACV 2026
              </b>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="todo" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-globe"></i>
                    </span>
                    <span>Conference</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.05424" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Experiment Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/PropGrad/Interventional-XAI" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns is-centered">
        <!-- Visual Effects. -->
        <div class="column has-text-centered">
          <div class="content">
            <h2 class="title is-2">Abstract</h2>
            <p style="font-size: 0.9rem;" class="is-centered">
              <div>&ensp;</div>
              <div>&ensp;</div>
              <div class="content has-text-justified">
              Deep learning models achieve high predictive performance but lack intrinsic interpretability, hindering our understanding of the learned prediction behavior.
              Existing local explainability methods focus on associations, neglecting the causal drivers of model predictions. 
              Other approaches adopt a causal perspective but primarily provide global, model-level explanations.
              However, for specific inputs, <strong>it's unclear whether globally identified factors apply locally.</strong>
              To address this limitation, we introduce a novel framework for local interventional explanations by leveraging recent advances in image-to-image editing models. 
              Our approach performs gradual interventions on semantic properties to <strong>quantify the corresponding impact on a model's predictions</strong> using a novel score, the <strong>expected property gradient magnitude</strong>. 
              We demonstrate the effectiveness of our approach through an extensive empirical evaluation on a wide range of architectures and tasks.
              First, we validate it in a synthetic scenario and demonstrate its <strong>ability to locally identify biases</strong>.
              Afterward, we apply our approach to investigate medical skin lesion classifiers, analyze network training dynamics, and study a pre-trained CLIP model with real-life interventional data.
              Our results highlight the potential of interventional explanations on the property level to reveal new insights into the behavior of deep models.
              </div>
            </p>
          </div>
        </div>
        <div class="column has-text-centered">
          <h2 class="title is-4">Example Interventions for <br> Cat vs. Dog Classifiers</h2>
          <div class="columns is-centered">
            <div class="column content">
              <!-- <div>&ensp;</div> -->
              <!-- <div>&ensp;</div> -->
              <img src="./static/images/teaser.png" class="interpolation-image" alt="Teaser Figure" width="1000" height="1000" />
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!--
  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Quantitative Comparison</h2>
            <p class="content has-text-justified">
              To empirically compare FastCAV with SVM-based computation, we evaluate a broad spectrum of model architectures trained on <a href="https://arxiv.org/abs/1409.0575">ImageNet</a>.
              We split our investigation into four dimensions: computational time, accuracy, inter-method similarity, and intra-method robustness.
            </p>
            <img src="./static/images/table.png" class="interpolation-image" alt="Interpolation end reference image." width="1000" />
            <p class="content has-text-justified">
              Comparing our approach FastCAV with SVM-based computation. <b>Bold values</b> indicate better results.
              "N/A" indicates that no results were produced due to the overall computational time exceeding four days. 
              More details can be found in our paper!
            </p>
          </div>
        </div>
  </section>

  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Qualitative Comparison</h2>
            <p class="content has-text-justified">
              FastCAV can act as a more efficient drop-in replacement for downstream applications of CAVs. 
              Examples include Testing with Concept Activation Vectors <a href="https://arxiv.org/abs/1711.11279">(TCAV)</a> or Automatic Concept-based Explanations <a href="https://arxiv.org/abs/1902.03129">(ACE)</a>.
            </p>

            <h3 class="title is-4">Testing for Class Relevant Concepts with TCAV </h3>
            <img src="./static/images/tcav.png" class="interpolation-image" alt="Interpolation end reference image." width="1000" />
            <p class="content has-text-justified">
              TCAV scores for various <a href="https://arxiv.org/abs/1409.4842">GoogleNet</a> layers.
              We compare the concepts "polka-dotted", "striped", and "zigzagged" for the class <i>ladybug</i> using FastCAV against the established SVM approach.
              We mark CAVs that are not statistically significant with "*".
              The insights into the GoogleNet model are consistent between both our approach and the SVM-based method.
              Nevertheless, we observe <strong>lower standard deviations</strong> and <strong>faster computation speed</strong> for FastCAV.
            </p>

            <h3 class="title is-4">Automatic Concept Discovery with ACE </h3>
            <img src="./static/images/ace.png" class="interpolation-image" alt="Interpolation end reference image." width="600" />
            <p class="content has-text-justified">
              Comparison of the most salient concepts discovered by ACE using either our FastCAV or the established SVM-CAV. 
              Here, we use class <i>lionfish</i> and display the two most salient concepts. 
              We find the discovered patches between both approaches <b>similar and congruent with the original observation</b> in <a href="https://arxiv.org/abs/1902.03129">(Ghorbani et al., 2019)</a>.
            </p>
          </div>
        </div>
  </section>


  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Tracking CAVs During Training Using FastCAV</h2>
            <p class="content has-text-justified">
              FastCAV enables previously infeasible analyses for models with high dimensional activation spaces. 
              To show this, we train a <a href="https://arxiv.org/abs/1512.03385">ResNet50</a> on <a href="https://arxiv.org/abs/1409.0575">ImageNet</a> from scratch and track the evolution of learned concepts during training.  
            </p>
            <img src="./static/images/training-ana.png" class="interpolation-image" alt="Interpolation end reference image." width="1000" />
            <p class="content has-text-justified">
              We find the learning of concepts aligns with a simultaneous increase in predictive performance, suggesting that the model is learning to recognize and utilize relevant information for predictions.
              We observe similar trends for specific concept examples, although the results exhibit increased variability across the training steps compared to the average across concepts.
              Notably, we observe stark increases in average CAV accuracy after each epoch, where the learning rate is reduced during training.
            </p>
            <p class="content has-text-justified">
              Furthermore, we observe that early and middle layers have a higher likelihood of learning textures compared to later layers, supporting previous findings (<a href="https://arxiv.org/abs/1711.11279">Kim et al., 2018</a>; <a href="https://arxiv.org/abs/1902.03129">Ghorbani et al., 2019</a>; <a href="https://arxiv.org/abs/1704.05796">Bau et al., 2017</a>). 
              Our observations demonstrate that FastCAV can be used to study the learning dynamics of deep neural networks in a more fine-grained manner and for abstract concepts.
            </p>
          </div>
        </div>
  </section> -->
  

  <section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
      <h2 class="title">BibTeX</h2>
      <p class="content has-text-justified">
        If you find our work useful, please consider citing our paper!
      </p>
      <pre>
      <code>
@inproceedings{penzel2025towards,
    author = {Niklas Penzel and Joachim Denzler},
    title = {Towards Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients},
    year = {2025},
    doi = {10.48550/arXiv.2503.05424},
    arxiv = {https://arxiv.org/abs/2503.05424},
    note = {accepted at WACV 2026},
}</code>
      </pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://icml.cc/virtual/2025/poster/44251">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/cvjena" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
              The source code of this site is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
              We thank its creators for their work. 
            </p>
            <br><a rel="license" href="impressum_privacy.html">Impressum and Data privacy</a>.
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>
